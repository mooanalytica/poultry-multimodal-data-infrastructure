{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7706e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "video_illumination_correction.ipynb\n",
    "\n",
    "Illumination correction pipeline for longitudinal multimodal poultry monitoring dataset.\n",
    "\n",
    "Applies brightness, contrast, and hue adjustments to raw MP4 video clips recorded\n",
    "under variable barn lighting conditions. Parameters were calibrated using CapCut\n",
    "for visual inspection and then implemented programmatically using OpenCV for\n",
    "automated batch processing.\n",
    "\n",
    "Input folder structure expected:\n",
    "    Sample_Dataset/\n",
    "    └── Video/\n",
    "          └── *.mp4\n",
    "\n",
    "Output files are saved in:\n",
    "    Sample_Dataset/\n",
    "    └── Video_Processed/\n",
    "          └── *_processed.mp4\n",
    "\n",
    "Parameters (fixed as per manuscript, Section 4.3):\n",
    "    - Brightness:  +25% via linear scaling (alpha = 1.25, beta = 0)\n",
    "    - Contrast:    +10% (applied via HSV value channel scaling)\n",
    "    - Hue:         +20% (applied via HSV hue channel shift)\n",
    "\n",
    "Dependencies:\n",
    "    pip install opencv-python tqdm numpy\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1437558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PARAMETERS — fixed values as reported in manuscript (Section 4.3)\n",
    "# =============================================================================\n",
    "\n",
    "BRIGHTNESS_ALPHA = 1.55\n",
    "BRIGHTNESS_BETA  = 0\n",
    "CONTRAST_SCALE   = 1.20\n",
    "HUE_SHIFT        = -2 # minor correction to neutralise warm barn lighting\n",
    "\n",
    "INPUT_DIR  = os.path.join(\"Sample_Dataset\", \"Video\")\n",
    "OUTPUT_DIR = os.path.join(\"Sample_Dataset\", \"Video_Processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b4b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FRAME-LEVEL CORRECTION\n",
    "# =============================================================================\n",
    "\n",
    "def apply_illumination_correction(frame):\n",
    "    # Brightness: linear scaling across all channels\n",
    "    frame_bright = cv2.convertScaleAbs(frame, alpha=BRIGHTNESS_ALPHA, beta=BRIGHTNESS_BETA)\n",
    "\n",
    "    # Convert to HSV for independent channel manipulation\n",
    "    hsv = cv2.cvtColor(frame_bright, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Contrast: scale Value channel, clip to [0, 255]\n",
    "    v = np.clip(v * CONTRAST_SCALE, 0, 255)\n",
    "\n",
    "    # Hue: shift Hue channel, wrap at 180 (OpenCV hue range)\n",
    "    h = (h + HUE_SHIFT) % 180\n",
    "\n",
    "    # Merge and convert back to BGR\n",
    "    hsv_corrected   = cv2.merge([h, s, v]).astype(np.uint8)\n",
    "    frame_corrected = cv2.cvtColor(hsv_corrected, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return frame_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f804f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SINGLE VIDEO PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"  [WARNING] Could not open: {input_path}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width        = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height       = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fourcc       = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out          = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"  Correcting frames\", unit=\"frame\", leave=False) as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            out.write(apply_illumination_correction(frame))\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a76eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BATCH PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "def run_batch_pipeline(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    video_files = [f for f in os.listdir(input_dir) if f.lower().endswith(\".mp4\")]\n",
    "\n",
    "    if not video_files:\n",
    "        print(f\"[INFO] No .mp4 files found in: {input_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  Video Illumination Correction Pipeline\")\n",
    "    print(f\"  Input  : {input_dir}\")\n",
    "    print(f\"  Output : {output_dir}\")\n",
    "    print(f\"  Files  : {len(video_files)}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    for idx, filename in enumerate(tqdm(video_files, desc=\"Overall progress\", unit=\"video\"), start=1):\n",
    "        input_path  = os.path.join(input_dir, filename)\n",
    "        base_name   = os.path.splitext(filename)[0]\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_processed.mp4\")\n",
    "\n",
    "        print(f\"[{idx}/{len(video_files)}] {filename}\")\n",
    "        process_video(input_path, output_path)\n",
    "        print(f\"  Saved → {base_name}_processed.mp4\\n\")\n",
    "\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Done. {len(video_files)} video(s) processed.\")\n",
    "    print(f\"  Output saved to: {output_dir}\")\n",
    "    print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98539992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Video Illumination Correction Pipeline\n",
      "  Input  : Sample_Dataset/Video\n",
      "  Output : Sample_Dataset/Video_Processed\n",
      "  Files  : 2\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:   0%|          | 0/2 [00:00<?, ?video/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Barn1_SampleClip_5Sept.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  50%|█████     | 1/2 [00:39<00:39, 39.58s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved → Barn1_SampleClip_5Sept_processed.mp4\n",
      "\n",
      "[2/2] Barn3_SampleClip_25Aug.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress: 100%|██████████| 2/2 [01:18<00:00, 39.05s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved → Barn3_SampleClip_25Aug_processed.mp4\n",
      "\n",
      "============================================================\n",
      "  Done. 2 video(s) processed.\n",
      "  Output saved to: Sample_Dataset/Video_Processed\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RUN\n",
    "# =============================================================================\n",
    "\n",
    "run_batch_pipeline(INPUT_DIR, OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
